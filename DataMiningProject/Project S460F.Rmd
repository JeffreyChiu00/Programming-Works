---
title: "Final Project"
author: "Jeffrey CHIU"
date: "2020/12/28"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Packages Install
```{r pack-list, eval=FALSE}
install.packages("dplyr")
install.packages("tidyr")
install.packages("ggplot2")
install.packages("glmnet")
install.packages("pls")
install.packages("leaps")
install.packages("e1071")
install.packages("ROCR")
install.packages("ggpubr")
```

# Loading Packages
```{r load-pack}
library(dplyr)
library(tidyr)
library(ggplot2)
library(glmnet)
library(pls)
library(leaps)
library(e1071)
library(ROCR)
library(ggpubr)
```

# Dataset
```{r}
Mydata = data.frame(read.csv("C:\\CoLI2020.csv"))
Mydata = Mydata[3:7]

x = model.matrix(cost_of_living_index~., Mydata)[,-1]
y = Mydata %>%
  select(cost_of_living_index) %>%
  unlist() %>%
  as.numeric()

train = Mydata %>%
  sample_frac(0.5)
test = Mydata %>%
  setdiff(train)

x_train = model.matrix(cost_of_living_index~., train)[,-1]
x_test = model.matrix(cost_of_living_index~., test)[,-1]

y_train = train %>%
  select(cost_of_living_index) %>%
  unlist() %>%
  as.numeric()

y_test = test %>%
  select(cost_of_living_index) %>%
  unlist() %>%
  as.numeric()
```

# Make the descriptive and exploratory analysis of each variable and interpret their findings.
```{r}
summary(Mydata$cost_of_living_index)
summary(Mydata$rent_index)
summary(Mydata$groceries_index)
summary(Mydata$restaurant_price_index)
summary(Mydata$local_purchasing_power_index)

hist(Mydata$cost_of_living_index, main="Cost of Living Index")
hist(Mydata$rent_index, main="Rent Index")
hist(Mydata$groceries_index, main="Groceries Index")
hist(Mydata$restaurant_price_index, main="Restaurant Price Index")
hist(Mydata$local_purchasing_power_index, main="Local Purchasing Power Index")

boxplot(Mydata$cost_of_living_index, main="Cost of Living Index")
boxplot(Mydata$rent_index, main="Rent Index")
boxplot(Mydata$groceries_index, main="Groceries Index")
boxplot(Mydata$restaurant_price_index, main="Restaurant Price Index")
boxplot(Mydata$local_purchasing_power_index, main="Local Purchasing Power Index")
```

#  Correlation plots 
```{r}
plot(Mydata$rent_index, Mydata$cost_of_living_index)
plot(Mydata$groceries_index, Mydata$cost_of_living_index)
plot(Mydata$restaurant_price_index, Mydata$cost_of_living_index)
plot(Mydata$local_purchasing_power_index, Mydata$cost_of_living_index)
cor(Mydata, Mydata$cost_of_living_index)
```

# Ridge regression
```{r}
grid = 10^seq(10, -2, length = 100)
ridge_mod = glmnet(x_train, y_train, alpha=0, lambda = grid, thresh = 1e-12)
plot(ridge_mod)

ridge_pred = predict(ridge_mod, s = 4, newx = x_test)
ridge_pred = predict(ridge_mod, s = 1e10, newx = x_test)

set.seed(1)
cv.out = cv.glmnet(x_train, y_train, alpha = 0)
bestlam = cv.out$lambda.min
bestlam

plot(cv.out)

ridge_pred = predict(ridge_mod, s = bestlam, newx = x_test)
mean((ridge_pred - y_test)^2) #Testing Mean Square Error

out = glmnet(x, y, alpha = 0)
predict(out, type = "coefficients", s = bestlam)[1:5,] #Coefficients
```

# Lasso regression
```{r}
lasso_mod = glmnet(x_train, y_train, alpha = 1, lambda = grid)
plot(lasso_mod)

set.seed(1)
cv.out = cv.glmnet(x_train, y_train, alpha = 1)
plot(cv.out)

bestlam = cv.out$lambda.min
bestlam

lasso_pred = predict(lasso_mod, s = bestlam, newx = x_test)
mean((lasso_pred - y_test)^2) #Testing Mean Square Error

out = glmnet(x, y, alpha = 1, lambda = grid)
predict(out, type = "coefficients", s = bestlam)[1:5,] #Coefficients
```

# SVM
```{r}
data = read.csv("C:\\CoLI2020.csv")

data = data[3:7]
groceries_index = data$groceries_index
restaurant_price_index = data$restaurant_price_index
class = cut(data$cost_of_living_index, c(0, 56, 92, Inf), labels = c("Low","Medium","High"))

Newdata = data.frame(+groceries_index, +restaurant_price_index)

ggplot(data.frame(data), aes(groceries_index, restaurant_price_index, colour = factor(class)))+
  geom_point()
```

```{r}
data = data.frame(x=Newdata, class=as.factor(class))

train_newdata = data %>%
  sample_frac(0.5)

test_newdata = data %>%
  setdiff(train_newdata)
```

```{r}
set.seed(1)
tune_out = tune(svm, class~., data=train_newdata, kernel="linear", ranges=list(cost=c(0.1, 1, 5, 10, 100)))
summary(tune_out)
bestmod = tune_out$best.model
plot(bestmod, train_newdata)
summary(bestmod)
```

```{r}
class_pred = predict(bestmod, test_newdata)
table = table(predicted=class_pred, true=test_newdata$class)
accuracy = (((table[1,1]+ table[2,2]+ table[3,3]))/ count(test_newdata))

table
accuracy #Accuracy
```
